{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "with open('data/test/test_text.txt', 'r') as f:\n",
    "    data = [line.strip().strip('.') for line in f.readlines()]\n",
    "test_peoples = [d for d in data if (' female' in d or ' woman' in d or ' male' in d or ' man' in d)]\n",
    "test_cars = [d for d in data if not (' female' in d or ' woman' in d or ' male' in d or ' man' in d)]\n",
    "# test_cars = data[:7611]\n",
    "# test_peoples = data[7611:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text-to-Code (People)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_codes = np.zeros((len(test_peoples), 30), dtype=np.int32)\n",
    "# 0-1, 2-4, 5-7, 8-9, 10-11, 12-13, 14-16, 17-18, 19-20, 21-25, 26-27, 28-29\n",
    "for idx, cap in enumerate(test_peoples):\n",
    "    if ' female' in cap or ' woman' in cap:\n",
    "        test_codes[idx, 0] = 1\n",
    "    else:\n",
    "        test_codes[idx, 1] = 1\n",
    "    if 'aged 60 or older' in cap or 'over 60' in cap or 'at least 60 years old' in cap:\n",
    "        test_codes[idx, 2] = 1\n",
    "    elif 'between 18 and 60 years old' in cap or 'aged 18-60' in cap:\n",
    "        test_codes[idx, 3] = 1\n",
    "    elif 'is a minor' in cap or 'age 18 or younger' in cap or 'not an adult' in cap or 'less than 18 years old' in cap:\n",
    "        test_codes[idx, 4] = 1\n",
    "    if 'body facing the camera' in cap:\n",
    "        test_codes[idx, 5] = 1\n",
    "    elif 'standing sideways' in cap:\n",
    "        test_codes[idx, 6] = 1\n",
    "    elif 'body back to the camera' in cap:\n",
    "        test_codes[idx, 7] = 1\n",
    "    if 'wearning a hat' in cap:\n",
    "        test_codes[idx, 8] = 1\n",
    "    if 'glasses' in cap:\n",
    "        test_codes[idx, 10] = 1\n",
    "    if 'handbag' in cap:\n",
    "        test_codes[idx, 12] = 1\n",
    "    if 'shoulderbag' in cap or 'is carrying a shoulder bag' in cap or 'has a bag over the shoulder' in cap:\n",
    "        test_codes[idx, 14] = 1\n",
    "    elif 'backpack' in cap:\n",
    "        test_codes[idx, 15] = 1\n",
    "    if 'holds objects in front' in cap:\n",
    "        test_codes[idx, 17] = 1\n",
    "    if 'short sleeve' in cap:\n",
    "        test_codes[idx, 19] = 1\n",
    "    elif 'long sleeve' in cap:\n",
    "        test_codes[idx, 20] = 1\n",
    "    if 'upper stripe' in cap:\n",
    "        test_codes[idx, 21] = 1\n",
    "    elif 'upper logo' in cap or 'logo on the upper' in cap:\n",
    "        test_codes[idx, 22] = 1\n",
    "    elif 'upper plaid' in cap or 'plaid on the upper' in cap:\n",
    "        test_codes[idx, 23] = 1\n",
    "    elif 'upper splice' in cap or 'splice on the upper' in cap:\n",
    "        test_codes[idx, 24] = 1\n",
    "    if 'coat' in cap:\n",
    "        test_codes[idx, 26] = 1\n",
    "    if 'skirt or dress' in cap:\n",
    "        test_codes[idx, 28] = 1\n",
    "\n",
    "code_str = [str(code) for code in test_codes]\n",
    "df = pd.DataFrame({'prompt':test_peoples, 'code':code_str})\n",
    "df.to_csv('data/test/test_people.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text-to-Code (Car)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'prompt':test_cars})\n",
    "df1 = pd.read_csv('data/car_text/car_types.csv')\n",
    "df2 = pd.read_csv('data/car_text/car_colors.csv')\n",
    "df3 = pd.read_csv('data/car_text/car_brands.csv')\n",
    "types = df1['type_name'].tolist()\n",
    "colors = df2['color_name'].tolist()\n",
    "brands = df3['brand_name'].tolist()\n",
    "df['type'] = np.nan\n",
    "df['color'] = np.nan\n",
    "df['brand'] = np.nan\n",
    "for i, code in enumerate(test_cars):\n",
    "    for t in types:\n",
    "        if t in code.split():\n",
    "            df.loc[i, 'type'] = types.index(t)\n",
    "    for c in colors:\n",
    "        if c in code.split():\n",
    "            df.loc[i, 'color'] = colors.index(c)\n",
    "    for b in brands:\n",
    "        if len(b.split()) == 2:\n",
    "            if b in code:\n",
    "                df.loc[i, 'brand'] = brands.index(b)\n",
    "        elif b in code.split():\n",
    "            df.loc[i, 'brand'] = brands.index(b)\n",
    "\n",
    "df.to_csv('data/test/test_car.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### People emsenble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python CVPR/inference_people_cl_emsenble.py \\\n",
    "--csv-dir data/test/test_people.csv \\\n",
    "--config_names config_eva_vit_people_cl config_eva_vit_people_cl config_eva_02_people_cl \\\n",
    "--image-sizes 224 336 448 \\\n",
    "--model-weights 0.35 0.15 0.5 \\\n",
    "--batch-size 32 \\\n",
    "--model_path1 \\\n",
    "    output/people/eva-l-people-0/eva-cl-l_best_ep8.pth \\\n",
    "    output/people/eva-l-people-1/eva-cl-l_best_ep8.pth \\\n",
    "    output/people/eva-l-people-2/eva-cl-l_best_ep8.pth \\\n",
    "    output/people/eva-l-people-3/eva-cl-l_best_ep8.pth \\\n",
    "    output/people/eva-l-people-4/eva-cl-l_best_ep8.pth \\\n",
    "    output/people/eva-l-people-5/eva-cl-l_best_ep8.pth \\\n",
    "    output/people/eva-l-people-6/eva-cl-l_best_ep8.pth \\\n",
    "    output/people/eva-l-people-7/eva-cl-l_best_ep8.pth \\\n",
    "    output/people/eva-l-people-8/eva-cl-l_best_ep8.pth \\\n",
    "    output/people/eva-l-people-9/eva-cl-l_best_ep8.pth \\\n",
    "    output/people/eva-l-people-10/eva-cl-l_best_ep8.pth \\\n",
    "    output/people/eva-l-people-11/eva-cl-l_best_ep8.pth \\\n",
    "--model_path2 \\\n",
    "    output/people/eva-l-336-people-0/eva-cl-l_best_ep8.pth \\\n",
    "    output/people/eva-l-336-people-1/eva-cl-l_best_ep8.pth \\\n",
    "    output/people/eva-l-336-people-2/eva-cl-l_best_ep8.pth \\\n",
    "    output/people/eva-l-336-people-3/eva-cl-l_best_ep8.pth \\\n",
    "    output/people/eva-l-336-people-4/eva-cl-l_best_ep8.pth \\\n",
    "    output/people/eva-l-336-people-5/eva-cl-l_best_ep8.pth \\\n",
    "    output/people/eva-l-336-people-6/eva-cl-l_best_ep8.pth \\\n",
    "    output/people/eva-l-336-people-7/eva-cl-l_best_ep8.pth \\\n",
    "    output/people/eva-l-336-people-8/eva-cl-l_best_ep8.pth \\\n",
    "    output/people/eva-l-336-people-9/eva-cl-l_best_ep8.pth \\\n",
    "    output/people/eva-l-336-people-10/eva-cl-l_best_ep8.pth \\\n",
    "    output/people/eva-l-336-people-11/eva-cl-l_best_ep8.pth \\\n",
    "--model_path3 \\\n",
    "    output/people/eva02-l-448-people-0/eva_02-448_best_ep8.pth \\\n",
    "    output/people/eva02-l-448-people-1/eva_02-448_best_ep8.pth \\\n",
    "    output/people/eva02-l-448-people-2/eva_02-448_best_ep8.pth \\\n",
    "    output/people/eva02-l-448-people-3/eva_02-448_best_ep8.pth \\\n",
    "    output/people/eva02-l-448-people-4/eva_02-448_best_ep8.pth \\\n",
    "    output/people/eva02-l-448-people-5/eva_02-448_best_ep8.pth \\\n",
    "    output/people/eva02-l-448-people-6/eva_02-448_best_ep8.pth \\\n",
    "    output/people/eva02-l-448-people-7/eva_02-448_best_ep8.pth \\\n",
    "    output/people/eva02-l-448-people-8/eva_02-448_best_ep8.pth \\\n",
    "    output/people/eva02-l-448-people-9/eva_02-448_best_ep8.pth \\\n",
    "    output/people/eva02-l-448-people-10/eva_02-448_best_ep8.pth \\\n",
    "    output/people/eva02-l-448-people-11/eva_02-448_best_ep8.pth \\\n",
    "--num-workers 8 \\\n",
    "--num-workers 8 \\\n",
    "--nbatch_log 300 \\\n",
    "--fold 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Car emsenble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python CVPR/inference_car_emsenble.py \\\n",
    "--csv-dir data/test/test_car.csv \\\n",
    "--config_names config_eva_02_car_cl config_conv_car_cl \\\n",
    "--image-sizes 448 320 \\\n",
    "--model-weights 0.7 0.3 \\\n",
    "--model_paths1 output/car/eva_02-car-type/eva_02-448_best_ep5.pth output/car/conv-car-type/convnext_xxlarge_best_ep5.pth \\\n",
    "--model_paths2 output/car/eva_02-car-color/eva_02-448_best_ep5.pth output/car/conv-car-color/convnext_xxlarge_best_ep5.pth \\\n",
    "--model_paths3 output/car/eva_02-car-brand/eva_02-448_best_ep5.pth output/car/conv-car-brand/convnext_xxlarge_best_ep5.pth \\\n",
    "--batch-size 32 \\\n",
    "--num-workers 8 \\\n",
    "--fold 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preds-to-csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "df = pd.read_csv('data/test/test_car.csv')\n",
    "preds = torch.load('output/car.pth')\n",
    "preds = preds.expand(100, 82)\n",
    "label_1 = torch.tensor(df['type'].tolist())\n",
    "label_2 = torch.tensor(df['color'].tolist())\n",
    "label_3 = torch.tensor(df['brand'].tolist())\n",
    "label_1 = F.one_hot(label_1.long(), 6).float()\n",
    "label_2 = F.one_hot(label_2.long(), 11).float()\n",
    "label_3 = F.one_hot(label_3.long(), 65).float()\n",
    "labels = torch.cat([label_1, label_2, label_3], dim=1)\n",
    "for i in range(len(labels)):\n",
    "    code = labels[i].unsqueeze(0).repeat(len(labels), 1)\n",
    "    mse = ((code-preds)*code).pow(2).sum(dim=1)\n",
    "    path_idx = mse.argsort(dim=0)\n",
    "    for j in range(10):\n",
    "        df.loc[i, f'img_{j}'] = paths[path_idx[j]]\n",
    "df.to_csv('output/test_car_out_.csv', index=False)\n",
    "print('Inference complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### csv-to-json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "df1 = pd.read_csv('output/test_people_out.csv')\n",
    "df2 = pd.read_csv('output/test_car_out.csv')\n",
    "data = {\n",
    "    'results':[]\n",
    "}\n",
    "for idx, row in tqdm(df2.iterrows(), total=len(df1)):\n",
    "    res = {'text':row.prompt+'.', 'image_names':[]}\n",
    "    for i in range(10):\n",
    "        res['image_names'].append(row[f'img_{i}'].split('/')[-1])\n",
    "    data['results'].append(res)\n",
    "for idx, row in tqdm(df1.iterrows(), total=len(df1)):\n",
    "    res = {'text':row.prompt+'.', 'image_names':[]}\n",
    "    for i in range(10):\n",
    "        res['image_names'].append(row[f'img_{i}'].split('/')[-1])\n",
    "    data['results'].append(res)\n",
    "\n",
    "with open('output/submission.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "dc1fdf8315257af72404463f1ae84f6485d5212ca50b6e6157cecf4644ce291f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
